# -*- coding: utf-8 -*-
"""mnist.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NTyZXjdz2gWTpZz7fQAqibI9CV4cJwYr
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Step 1: Load the MNIST dataset
mnist = fetch_openml('mnist_784', version=1)
X, y = mnist.data.astype(np.float32), mnist.target.astype(np.int32)

# Normalize pixel values to range [0,1]
X /= 255.0

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features for better training stability
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Step 2: Train models using Adam and SGD
def train_model(optimizer):
    model = MLPClassifier(hidden_layer_sizes=(128,), activation='relu', solver=optimizer,
                          max_iter=5, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)

# Train models with Adam and SGD optimizers
accuracy_adam = train_model('adam')
accuracy_sgd = train_model('sgd')

# Step 3: Compare accuracy values
optimizers = ['Adam', 'SGD']
accuracies = [accuracy_adam, accuracy_sgd]

# Step 4: Plot accuracy comparison
plt.figure(figsize=(6, 4))
plt.bar(optimizers, accuracies, color=['blue', 'orange'])
plt.ylim([0.85, 1.0])  # Set a reasonable accuracy range
plt.xlabel("Optimizer")
plt.ylabel("Validation Accuracy")
plt.title("Adam vs. SGD Optimizer Performance on MNIST")
plt.show()